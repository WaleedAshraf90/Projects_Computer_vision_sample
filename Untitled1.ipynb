{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f098d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-ff784f6d0588>:86: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  with webdriver.Chrome(executable_path=driver_path) as wd:\n",
      "<ipython-input-1-ff784f6d0588>:26: DeprecationWarning: find_elements_by_css_selector is deprecated. Please use find_elements(by=By.CSS_SELECTOR, value=css_selector) instead\n",
      "  thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 100 search results. Extracting links from 0:100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-ff784f6d0588>:40: DeprecationWarning: find_elements_by_css_selector is deprecated. Please use find_elements(by=By.CSS_SELECTOR, value=css_selector) instead\n",
      "  actual_images = wd.find_elements_by_css_selector('img.n3VNCb')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 0 image links, looking for more ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ff784f6d0588>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m# num of images you can pass it from here  by default it's 10 if you are not passing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;31m# number_images = 10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[0msearch_and_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDRIVER_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-ff784f6d0588>\u001b[0m in \u001b[0;36msearch_and_download\u001b[1;34m(search_term, driver_path, target_path, number_images)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mpersist_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "def fetch_image_urls(query: str, max_links_to_fetch: int, wd: webdriver, sleep_between_interactions: int = 1):\n",
    "    def scroll_to_end(wd):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(sleep_between_interactions)\n",
    "\n",
    "        # build the google query\n",
    "\n",
    "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\n",
    "\n",
    "    # load the page\n",
    "    wd.get(search_url.format(q=query))\n",
    "\n",
    "    image_urls = set()\n",
    "    image_count = 0\n",
    "    results_start = 0\n",
    "    while image_count < max_links_to_fetch:\n",
    "        scroll_to_end(wd)\n",
    "\n",
    "        # get all image thumbnail results\n",
    "        thumbnail_results = wd.find_elements_by_css_selector(\"img.Q4LuWd\")\n",
    "        number_results = len(thumbnail_results)\n",
    "\n",
    "        print(f\"Found: {number_results} search results. Extracting links from {results_start}:{number_results}\")\n",
    "\n",
    "        for img in thumbnail_results[results_start:number_results]:\n",
    "            # try to click every thumbnail such that we can get the real image behind it\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(sleep_between_interactions)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            # extract image urls\n",
    "            actual_images = wd.find_elements_by_css_selector('img.n3VNCb')\n",
    "            for actual_image in actual_images:\n",
    "                if actual_image.get_attribute('src') and 'http' in actual_image.get_attribute('src'):\n",
    "                    image_urls.add(actual_image.get_attribute('src'))\n",
    "\n",
    "            image_count = len(image_urls)\n",
    "\n",
    "            if len(image_urls) >= max_links_to_fetch:\n",
    "                print(f\"Found: {len(image_urls)} image links, done!\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Found:\", len(image_urls), \"image links, looking for more ...\")\n",
    "            time.sleep(30)\n",
    "            return\n",
    "            load_more_button = wd.find_element_by_css_selector(\".mye4qd\")\n",
    "            if load_more_button:\n",
    "                wd.execute_script(\"document.querySelector('.mye4qd').click();\")\n",
    "\n",
    "        # move the result startpoint further down\n",
    "        results_start = len(thumbnail_results)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "def persist_image(folder_path:str,url:str, counter):\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not download {url} - {e}\")\n",
    "\n",
    "    try:\n",
    "        f = open(os.path.join(folder_path, 'jpg' + \"_\" + str(counter) + \".jpg\"), 'wb')\n",
    "        f.write(image_content)\n",
    "        f.close()\n",
    "        print(f\"SUCCESS - saved {url} - as {folder_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR - Could not save {url} - {e}\")\n",
    "\n",
    "\n",
    "def search_and_download(search_term: str, driver_path: str, target_path='./images', number_images=10):\n",
    "    target_folder = os.path.join(target_path, '_'.join(search_term.lower().split(' ')))\n",
    "\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\n",
    "        res = fetch_image_urls(search_term, number_images, wd=wd, sleep_between_interactions=0.5)\n",
    "\n",
    "    counter = 0\n",
    "    for elem in res:\n",
    "        persist_image(target_folder, elem, counter)\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "# How to execute this code\n",
    "# Step 1 : pip install selenium. pillow, requests\n",
    "# Step 2 : make sure you have chrome installed on your machine\n",
    "# Step 3 : Check your chrome version ( go to three dot then help then about google chrome )\n",
    "# Step 4 : Download the same chrome driver from here  \" https://chromedriver.storage.googleapis.com/index.html \"\n",
    "# Step 5 : put it inside the same folder of this code\n",
    "\n",
    "\n",
    "DRIVER_PATH = './chromedriver'\n",
    "search_term = 'Dog'\n",
    "# num of images you can pass it from here  by default it's 10 if you are not passing\n",
    "# number_images = 10\n",
    "search_and_download(search_term=search_term, driver_path=DRIVER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151f7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "def fetch_img_links(search_string : str, max_fetch_links : int, wd : webdriver, sleep_between_interactions : float = 1):\n",
    "    def scroll_to_end(wd):\n",
    "        wd.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(sleep_between_interactions)\n",
    "\n",
    "    search_url = \"https://www.google.com/search?safe=off&site=&tbm=isch&source=hp&q={q}&oq={q}&gs_l=img\"\n",
    "\n",
    "    wd.get(search_url.format(q=search_string))\n",
    "\n",
    "    image_urls = set()\n",
    "    image_count = 0\n",
    "    results_start = 0\n",
    "    while image_count < max_fetch_links:\n",
    "        scroll_to_end(wd)\n",
    "        thumbnails_result = wd.find_elements_by_css_selector('img.Q4LuWd')\n",
    "        number_result = len(thumbnails_result)\n",
    "\n",
    "        print(f'Found {number_result} images. Extracting images from {results_start} : {number_result}]')\n",
    "\n",
    "        for img in thumbnails_result[results_start:number_result]:\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(sleep_between_interactions)\n",
    "            except:\n",
    "                continue\n",
    "            actual_images = wd.find_elements_by_css_selector('img.n3VNCb')\n",
    "\n",
    "            for actual_image in actual_images:\n",
    "                if actual_image.get_attribute('src') and \"https\" in actual_image.get_attribute(\"src\"):\n",
    "                    image_urls.add(actual_image.get_attribute('src'))\n",
    "\n",
    "            image_count = len(image_urls)\n",
    "\n",
    "            if image_count >= max_fetch_links:\n",
    "                print(f'Found {image_count} image links and done...')\n",
    "                break\n",
    "        else:\n",
    "            print(f'Found {image_count} image urls. Looking for more.....')\n",
    "            time.sleep(sleep_between_interactions)\n",
    "            load_more_button = wd.find_elements_by_css_selector('.mye4qd')\n",
    "\n",
    "            if load_more_button:\n",
    "                wd.execute_script(\"document.querySelector('.mye4qd').click();\")\n",
    "\n",
    "        results_start = len(thumbnails_result)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "def persist_images(folder_path : str, url : str, counter):\n",
    "    try:\n",
    "        image_content = requests.get(url).content\n",
    "    except Exception as e:\n",
    "        print(f'Error has occured for {url} - {e}')\n",
    "\n",
    "    try:\n",
    "        f = open(os.path.join(folder_path, 'jpg_'+str(counter)+'.jpg'), 'wb')\n",
    "        f.write(image_content)\n",
    "        f.close()\n",
    "        print(f'Successfully Downloaded {url}')\n",
    "    except Exception as e:\n",
    "        print(f'Error has occured {url} - {e}')\n",
    "\n",
    "\n",
    "def search_and_download(search_term : str, driver_path = str, target_path = \"./images\", number_images : int = 10):\n",
    "    target_folder= os.path.join(target_path, \"_\".join(search_term.lower().split(' ')))\n",
    "\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    with webdriver.Chrome(executable_path=driver_path) as wd:\n",
    "        res = fetch_img_links(search_string=search_term, max_fetch_links=number_images, wd=wd, sleep_between_interactions=0.5)\n",
    "\n",
    "    counter = 0\n",
    "    for ele in res:\n",
    "        persist_images(folder_path=target_folder, url=ele, counter=counter)\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "term = 'Narendra Modi'\n",
    "path = r'C:\\Users\\Asus\\PycharmProjects\\ImageScrapper1\\chromedriver.exe'\n",
    "number = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c544acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Jul 18 13:01:02 2020\n",
    "\n",
    "@author: OHyic\n",
    "\"\"\"\n",
    "#import selenium drivers\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#import helper libraries\n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "class GoogleImageScraper():\n",
    "    def __init__(self, webdriver_path, image_path, search_key=\"cat\", number_of_images=1, headless=True, min_resolution=(0, 0), max_resolution=(1920, 1080), max_missed=10):\n",
    "        #check parameter types\n",
    "        image_path = os.path.join(image_path, search_key)\n",
    "        if (type(number_of_images)!=int):\n",
    "            print(\"[Error] Number of images must be integer value.\")\n",
    "            return\n",
    "        if not os.path.exists(image_path):\n",
    "            print(\"[INFO] Image path not found. Creating a new folder.\")\n",
    "            os.makedirs(image_path)\n",
    "            \n",
    "        #check if chromedriver is installed\n",
    "        if (not os.path.isfile(webdriver_path)):\n",
    "            is_patched = patch.download_lastest_chromedriver()\n",
    "            if (not is_patched):\n",
    "                exit(\"[ERR] Please update the chromedriver.exe in the webdriver folder according to your chrome version:https://chromedriver.chromium.org/downloads\")\n",
    "\n",
    "        for i in range(1):\n",
    "            try:\n",
    "                #try going to www.google.com\n",
    "                options = Options()\n",
    "                if(headless):\n",
    "                    options.add_argument('--headless')\n",
    "                driver = webdriver.Chrome(webdriver_path, chrome_options=options)\n",
    "                driver.set_window_size(1400,1050)\n",
    "                driver.get(\"https://www.google.com\")\n",
    "                try:\n",
    "                    WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, \"W0wltc\"))).click()\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                #update chromedriver\n",
    "                pattern = '(\\d+\\.\\d+\\.\\d+\\.\\d+)'\n",
    "                version = list(set(re.findall(pattern, str(e))))[0]\n",
    "                is_patched = patch.download_lastest_chromedriver(version)\n",
    "                if (not is_patched):\n",
    "                    exit(\"[ERR] Please update the chromedriver.exe in the webdriver folder according to your chrome version:https://chromedriver.chromium.org/downloads\")\n",
    "\n",
    "        self.driver = driver\n",
    "        self.search_key = search_key\n",
    "        self.number_of_images = number_of_images\n",
    "        self.webdriver_path = webdriver_path\n",
    "        self.image_path = image_path\n",
    "        self.url = \"https://www.google.com/search?q=%s&source=lnms&tbm=isch&sa=X&ved=2ahUKEwie44_AnqLpAhUhBWMBHUFGD90Q_AUoAXoECBUQAw&biw=1920&bih=947\"%(search_key)\n",
    "        self.headless=headless\n",
    "        self.min_resolution = min_resolution\n",
    "        self.max_resolution = max_resolution\n",
    "        self.max_missed = max_missed\n",
    "\n",
    "    def find_image_urls(self):\n",
    "        \"\"\"\n",
    "            This function search and return a list of image urls based on the search key.\n",
    "            Example:\n",
    "                google_image_scraper = GoogleImageScraper(\"webdriver_path\",\"image_path\",\"search_key\",number_of_photos)\n",
    "                image_urls = google_image_scraper.find_image_urls()\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Gathering image links\")\n",
    "        self.driver.get(self.url)\n",
    "        image_urls=[]\n",
    "        count = 0\n",
    "        missed_count = 0\n",
    "        indx_1 = 0\n",
    "        indx_2 = 0\n",
    "        search_string = '//*[@id=\"islrg\"]/div[1]/div[%s]/a[1]/div[1]/img'\n",
    "        time.sleep(3)\n",
    "        while self.number_of_images > count and missed_count < self.max_missed:\n",
    "            if indx_2 > 0:\n",
    "                try:\n",
    "                    imgurl = self.driver.find_element(By.XPATH, search_string%(indx_1,indx_2+1))\n",
    "                    imgurl.click()\n",
    "                    indx_2 = indx_2 + 1\n",
    "                    missed_count = 0\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        imgurl = self.driver.find_element(By.XPATH, search_string%(indx_1+1,1))\n",
    "                        imgurl.click()\n",
    "                        indx_2 = 1\n",
    "                        indx_1 = indx_1 + 1\n",
    "                    except:\n",
    "                        indx_2 = indx_2 + 1\n",
    "                        missed_count = missed_count + 1\n",
    "            else:\n",
    "                try:\n",
    "                    imgurl = self.driver.find_element(By.XPATH, search_string%(indx_1+1))\n",
    "                    imgurl.click()\n",
    "                    missed_count = 0\n",
    "                    indx_1 = indx_1 + 1    \n",
    "                except Exception:\n",
    "                    try:\n",
    "                        imgurl = self.driver.find_element(By.XPATH, '//*[@id=\"islrg\"]/div[1]/div[%s]/div[%s]/a[1]/div[1]/img'%(indx_1,indx_2+1))\n",
    "                        imgurl.click()\n",
    "                        missed_count = 0\n",
    "                        indx_2 = indx_2 + 1\n",
    "                        search_string = '//*[@id=\"islrg\"]/div[1]/div[%s]/div[%s]/a[1]/div[1]/img'\n",
    "                    except Exception:\n",
    "                        indx_1 = indx_1 + 1\n",
    "                        missed_count = missed_count + 1\n",
    "                    \n",
    "            try:\n",
    "                #select image from the popup\n",
    "                time.sleep(1)\n",
    "                class_names = [\"n3VNCb\",\"iPVvYb\",\"r48jcc\",\"pT0Scc\"]\n",
    "                images = [self.driver.find_elements(By.CLASS_NAME, class_name) for class_name in class_names if len(self.driver.find_elements(By.CLASS_NAME, class_name)) != 0 ][0]\n",
    "                for image in images:\n",
    "                    #only download images that starts with http\n",
    "                    src_link = image.get_attribute(\"src\")\n",
    "                    if((\"http\" in src_link) and (not \"encrypted\" in src_link)):\n",
    "                        print(\n",
    "                            f\"[INFO] {self.search_key} \\t #{count} \\t {src_link}\")\n",
    "                        image_urls.append(src_link)\n",
    "                        count +=1\n",
    "                        break\n",
    "            except Exception:\n",
    "                print(\"[INFO] Unable to get link\")\n",
    "\n",
    "            try:\n",
    "                #scroll page to load next image\n",
    "                if(count%3==0):\n",
    "                    self.driver.execute_script(\"window.scrollTo(0, \"+str(indx_1*60)+\");\")\n",
    "                element = self.driver.find_element(By.CLASS_NAME,\"mye4qd\")\n",
    "                element.click()\n",
    "                print(\"[INFO] Loading next page\")\n",
    "                time.sleep(3)\n",
    "            except Exception:\n",
    "                time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "        self.driver.quit()\n",
    "        print(\"[INFO] Google search ended\")\n",
    "        return image_urls\n",
    "\n",
    "    def save_images(self,image_urls, keep_filenames):\n",
    "        print(keep_filenames)\n",
    "        #save images into file directory\n",
    "        \"\"\"\n",
    "            This function takes in an array of image urls and save it into the given image path/directory.\n",
    "            Example:\n",
    "                google_image_scraper = GoogleImageScraper(\"webdriver_path\",\"image_path\",\"search_key\",number_of_photos)\n",
    "                image_urls=[\"https://example_1.jpg\",\"https://example_2.jpg\"]\n",
    "                google_image_scraper.save_images(image_urls)\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Saving image, please wait...\")\n",
    "        for indx,image_url in enumerate(image_urls):\n",
    "            try:\n",
    "                print(\"[INFO] Image url:%s\"%(image_url))\n",
    "                search_string = ''.join(e for e in self.search_key if e.isalnum())\n",
    "                image = requests.get(image_url,timeout=5)\n",
    "                if image.status_code == 200:\n",
    "                    with Image.open(io.BytesIO(image.content)) as image_from_web:\n",
    "                        try:\n",
    "                            if (keep_filenames):\n",
    "                                #extact filename without extension from URL\n",
    "                                o = urlparse(image_url)\n",
    "                                image_url = o.scheme + \"://\" + o.netloc + o.path\n",
    "                                name = os.path.splitext(os.path.basename(image_url))[0]\n",
    "                                #join filename and extension\n",
    "                                filename = \"%s.%s\"%(name,image_from_web.format.lower())\n",
    "                            else:\n",
    "                                filename = \"%s%s.%s\"%(search_string,str(indx),image_from_web.format.lower())\n",
    "\n",
    "                            image_path = os.path.join(self.image_path, filename)\n",
    "                            print(\n",
    "                                f\"[INFO] {self.search_key} \\t {indx} \\t Image saved at: {image_path}\")\n",
    "                            image_from_web.save(image_path)\n",
    "                        except OSError:\n",
    "                            rgb_im = image_from_web.convert('RGB')\n",
    "                            rgb_im.save(image_path)\n",
    "                        image_resolution = image_from_web.size\n",
    "                        if image_resolution != None:\n",
    "                            if image_resolution[0]<self.min_resolution[0] or image_resolution[1]<self.min_resolution[1] or image_resolution[0]>self.max_resolution[0] or image_resolution[1]>self.max_resolution[1]:\n",
    "                                image_from_web.close()\n",
    "                                os.remove(image_path)\n",
    "\n",
    "                        image_from_web.close()\n",
    "            except Exception as e:\n",
    "                print(\"[ERROR] Download failed: \",e)\n",
    "                pass\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"[INFO] Downloads completed. Please note that some photos were not downloaded as they were not in the correct format (e.g. jpg, jpeg, png)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557ea5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
